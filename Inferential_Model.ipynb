{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data manipulation and visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "\n",
    "#scaling module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#model optimzation modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "\n",
    "#model modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "\n",
    "#metric modules\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, roc_curve, recall_score, accuracy_score \n",
    "from sklearn.metrics import precision_score, confusion_matrix, precision_recall_curve, fbeta_score, auc, plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Inferential Model\n",
    "The first model to build is a simple model that while lacking the performance of our churn filter, will be easily digested in order to explore which aspects of customer profiles are contributing to churn and thusly give departure points to analyze the business practices that might contribute to these numbers. \n",
    "\n",
    "### Model Selection\n",
    "\n",
    "Two immediate models come to mind regarding simple/interpretable models for classification:\n",
    "* Logistic Regression\n",
    "    * When Data has a linear relationship.\n",
    "    * Simplest form as the Coefficents produced directly relate to the rate of change of each feature has on the model's Decision.\n",
    "* Decision Tree\n",
    "    * When Data does not have a linear relationship.\n",
    "    * Provides mapped out decision tree of how it came to decisions.\n",
    "    \n",
    "Addtionally to providing easily digestable results, these algorithms scale extremely well in performance and would be appropriate solutions to enterprise level of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "df = pd.read_csv(\"simple_preprocessed_scaled_df.csv\")\n",
    "df.head()\n",
    "\n",
    "#split data\n",
    "X, y = df.iloc[:,:12], df.iloc[:,-1]\n",
    "\n",
    "#train_test_split, 20% observations aside for testing, note will forgo validation split for this inferential exercise\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-31.5288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110042</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.5302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-42.5288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085945</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>-0.5302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-148.5288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110042</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>1.4698</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.4712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035934</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199.4712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133573</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>-0.5302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender       Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0     -31.5288       1  0.110042       2       0.00        -0.5302          1   \n",
       "1     -42.5288       1  0.085945       1   83807.86        -0.5302          0   \n",
       "2    -148.5288       1  0.110042       8  159660.80         1.4698          1   \n",
       "3      48.4712       1  0.035934       1       0.00         0.4698          0   \n",
       "4     199.4712       1  0.133573       2  125510.82        -0.5302          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  France  Germany  Spain  \n",
       "0               1        101348.88     1.0      0.0    0.0  \n",
       "1               1        112542.58     0.0      0.0    1.0  \n",
       "2               0        113931.57     1.0      0.0    0.0  \n",
       "3               0         93826.63     1.0      0.0    0.0  \n",
       "4               1         79084.10     0.0      0.0    1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62790406, 2.45459008])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data set is imbalanced (approx 20% of records are churrned) so I will calculate the class weights as an input to the LogisticRegression model\n",
    "df_class_weights= compute_class_weight('balanced', classes=[0,1], y=y)\n",
    "df_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model optimziation, I will utlized ROC AUC as my lead scoring metric, as I want to optimize the model's ability to find the largest boundary between TPR/FPR.\n",
    "\n",
    "Lets start by running a quick cross validation on both model types to see if there is any substantial difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Avg Area Under the ROC curve for Logistic Regression Classification averages: 0.7704\n",
      "The Avg Area Under the ROC curve for Decision Tree Classification averages: 0.682\n"
     ]
    }
   ],
   "source": [
    "#scaling data to optimize data for LogisiticRegression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log_reg_cv = cross_val_score(LogisticRegression(class_weight={0:0.62790406, 1:2.45459008}), X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "dec_tree_cv = cross_val_score(DecisionTreeClassifier(class_weight={0:0.62790406, 1:2.45459008}), X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('The Avg Area Under the ROC curve for Logistic Regression Classification averages: ' + str(round(np.mean(log_reg_cv),4)))\n",
    "print('The Avg Area Under the ROC curve for Decision Tree Classification averages: ' + str(round(np.mean(dec_tree_cv),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cross Val showed promising given the constraints of these models type. Considering the scalability of each algorithm I'll optimize each to validate my findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for LogisticRegressor\n",
    "\n",
    "l1_grid_params = {\n",
    "                    'solver' : ['liblinear', 'saga'],\n",
    "                    'C' : [i for i in range(11)],\n",
    "                    'max_iter' : [1000,5000,10000,50000]\n",
    "}\n",
    "\n",
    "l2_grid_params = {\n",
    "                    'solver' : ['newton-cg', 'lbfgs','sag', 'saga'],\n",
    "                    'C' : [i for i in range(11)],\n",
    "                    'max_iter' : [1000,5000,10000,50000]\n",
    "}\n",
    "\n",
    "en_grid_params = {\n",
    "                    'solver' : ['newton-cg', 'lbfgs','sag', 'saga'],\n",
    "                    'C' : [i for i in range(11)],\n",
    "                    'max_iter' : [1000,5000,10000,50000],\n",
    "                    'l1_ratio' : [.001, .01, .1, .25, .5, .75, .9, .99, .999]\n",
    "}\n",
    "\n",
    "log_params = [l1_grid_params, l2_grid_params, en_grid_params]\n",
    "log_penalty = ['l1','l2', 'elasticnet']\n",
    "\n",
    "for p_grid, log_penalty in zip(log_params, log_penalty):\n",
    "    grid = GridSearchCV(LogisticRegression(random_state = 42, class_weight={0:0.62790406, 1:2.45459008}, penalty=log_penalty), p_grid,cv = 10, scoring='roc_auc', error_score=np.nan, n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print('Penalty: ' + str(log_penalty))\n",
    "    print('Best Score: ' + str(grid.best_score_))\n",
    "    print('Best Esitmator: ' +str(grid.best_estimator_) +'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch produced similiar results among different solvers and Regulraization stengths. Chose best performing ElasticNet solver to apply to data and analyze the effects the parameters have on the churn potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#build helper function to display results of model fit on test data\n",
    "\n",
    "def results_pipe(model):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    print('Model Results')\n",
    "    print('Accuracy: ' + str(accuracy_score(y_test, model.predict(X_test_scaled))))\n",
    "    print('F1 ' + str(f1_score(y_test, model.predict(X_test_scaled))))\n",
    "    print('ROC AUC :' + str(roc_auc_score(y_test, model.predict(X_test_scaled)))+'\\n')\n",
    "    print(classification_report(y_test,model.predict(X_test_scaled))+'\\n')\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(40,12))\n",
    "    grid = plt.GridSpec(1, 4, wspace=0.3, hspace=0.4)\n",
    "    ax1 = plt.subplot(grid[0,0])\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(data=confusion, cmap=plt.cm.Blues, annot=True, square=True, fmt='g',\n",
    "           xticklabels=['Stay', 'Exit'],\n",
    "           yticklabels=['Stay', 'Exit'], ax=ax1)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(2):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test, y_pred)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    ax2 = plt.subplot(grid[0,1])    \n",
    "    sns.lineplot(x=fpr[1], y=tpr[1],label='LogisticRegression', ax=ax2)\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('Receiver operating characteristic')\n",
    "    sns.lineplot(x=[0,1],y=[0,1], label='Naive Classifier', ax=ax2)\n",
    "    ax2.legend(loc='best')\n",
    "    \n",
    "    ax3 = plt.subplot(grid[0,2])\n",
    "    plot_precision_recall_curve(model, X_test_scaled, y_test, ax=ax3);\n",
    "    \n",
    "    if str(model)[0] == 'L':\n",
    "        zipped_cols_coefs = list(zip(X.columns,model.coef_[0]))\n",
    "        coef_df = pd.DataFrame(zipped_cols_coefs,columns=['Feature','Coef'])\n",
    "        coef_df.Coef = round(coef_df.Coef,4)\n",
    "        coef_df.sort_values('Coef',ascending=False, key=abs)\n",
    "        coef_df.set_index('Feature')\n",
    "        coef_df = coef_df.sort_values('Coef', key=abs,ascending=False)\n",
    "        ax4 = plt.subplot(grid[0,3])\n",
    "        ax4 = sns.barplot(x=coef_df.Coef, y=coef_df.Feature,color='#4287f5')\n",
    "        yabs_max = 1\n",
    "        ax4.set_xlim(xmin=-yabs_max, xmax=yabs_max)\n",
    "        ax4.set_title('Logistic Regression Coefficients')\n",
    "    else:\n",
    "        zipped_cols_fi = list(zip(X.columns,model.feature_importances_))\n",
    "        fi_df = pd.DataFrame(zipped_cols_fi,columns=['Feature','Feature Importance'])\n",
    "        fi_df['Feature Importance'] = round(fi_df['Feature Importance'],4)\n",
    "        fi_df =fi_df.sort_values('Feature Importance',ascending=False, key=abs)\n",
    "        ax4 = plt.subplot(grid[0,3])\n",
    "        ax4 = sns.barplot(x=fi_df['Feature Importance'], y=fi_df.Feature, color='#4287f5')\n",
    "        yabs_max = 1\n",
    "        ax4.set_xlim(xmin=-yabs_max, xmax=yabs_max)\n",
    "        ax4.set_title('Decision Tree Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print and graph the results of fitting LogisticRegression model on the data\n",
    "\n",
    "results_pipe(LogisticRegression(C=1, class_weight={0: 0.62790406, 1: 2.45459008},\n",
    "                   l1_ratio=0.75, max_iter=5000, penalty='elasticnet',\n",
    "                   random_state=42, solver='saga'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression Results\n",
    "The fit of the Regression model provided moderate results as the classifer was somewhat adept at capturing more than 2/3rds of the positive class with the correct label although a considerable amount of miss classfication within the negative class did occur. Considering the imbalance between the classes it is not surprising that the model was able to have greater success in identifying the negative class(non-Exited/current) as displayed by the classification report and F1-score.\n",
    "\n",
    "In reiewing the model's Precision-Recall Curve, we can see that Precision for our Positive class maxes out around ~.85 so Type 1 Errors are an inevitable outcome of the model. Additionally we can observe that \n",
    "\n",
    "The model is showing considerable improvement over a baseline guessing estimate pltted along the ROC curve, so the findings should be insightful to which factors are contributing to the positive class.\n",
    "\n",
    "Observing at the coefficents, (noting they are all scaled to reflect the parameter's z-score) Age provides the greatest affect on the model's score followed by the binary inputs of IsActiveMember, Germany and Gender.\n",
    "\n",
    "Drawing your attention to the dataframe below, you can observe the baseline probability of the model chooseing the Positive (Exited) class in the non real world scenario of having all other units effect nullified (Scaled to 0/Parameter mean), along with each singular input's affect on the model when either activated as a binary input or adjusted by 1 Standard Deviation. As expected, Age holds the most considerable sway over the models adjustment in probability. Likely indicating that the Age input is a major contributor to customer base's churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression(C=1, class_weight={0: 0.62790406, 1: 2.45459008},\n",
    "                   l1_ratio=0.75, max_iter=5000, penalty='elasticnet',\n",
    "                   random_state=42, solver='saga')\n",
    "\n",
    "\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "\n",
    "effect_df = pd.DataFrame(columns=['Parameter', 'Parameter Probability', 'Delta From Baseline','Unit Change Represented'])\n",
    "base_input = np.zeros((12,))\n",
    "base_prob = lm.predict_proba(base_input.reshape(1,-1))[0][1]\n",
    "effect_df = effect_df.append({'Parameter':'Baseline', 'Parameter Probability': round(base_prob,4), 'Delta From Baseline': '--' , 'Unit Change Represented' : '--'}, ignore_index=True)\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    base_input = np.zeros((12,))\n",
    "    base_input[i] = 1\n",
    "    input_prob = lm.predict_proba(base_input.reshape(1,-1))[0][1]\n",
    "    effect_df = effect_df.append({'Parameter':X.columns[i], \n",
    "                                  'Parameter Probability': round(input_prob,4), \n",
    "                                  'Delta From Baseline': round(input_prob-base_prob,4),\n",
    "                                  'Unit Change Represented' : (lambda x : round(X.iloc[:,i].std(),2) if len(X.iloc[:,i].value_counts()) > 2 else 'Binary')(i)  }, ignore_index=True)\n",
    "\n",
    "\n",
    "effect_df.at[3,'Unit Change Represented'] = 10.49\n",
    "    \n",
    "effect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model\n",
    "\n",
    "with open('log_reg_model.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lm, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifer\n",
    "\n",
    "For the next step in the inferential analysis we will turn our attention to the DecisionTree or CART model. This relatively simple form of the tree models seeks to \"split\" the data using decision points within the ranges of the input parameters. Decision for the splits are made based on how \"pure\" the resulting node or leaf would be, commonly measured in 'Gini' or 'Entropy'. \n",
    "\n",
    "As the goal of this exercise is to pull simple inference to build a case of cause of customer churn. Lets start by analysing how a simple a model we can create while maintaining performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('simple_preprocessed_unscaled_df.csv')\n",
    "\n",
    "#split data\n",
    "X, y = df.iloc[:,:12], df.iloc[:,-1]\n",
    "\n",
    "#train_test_split, 20% observations aside for testing, note will forgo validation split for this inferential exercise\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_grid = {'max_depth':[i for i in range(1,10)]}\n",
    "\n",
    "f1_depth_grid  = GridSearchCV(DecisionTreeClassifier(random_state=42,class_weight={0:0.62790406, 1:2.45459008}), \n",
    "                     size_grid, cv = 10, scoring='f1',\n",
    "                    error_score=np.nan, n_jobs=-1)\n",
    "\n",
    "roc_depth_grid  = GridSearchCV(DecisionTreeClassifier(random_state=42,class_weight={0:0.62790406, 1:2.45459008}), \n",
    "                     size_grid, cv = 10, scoring='roc_auc',\n",
    "                    error_score=np.nan, n_jobs=-1)\n",
    "\n",
    "f1_depth_grid.fit(X, y)\n",
    "roc_depth_grid.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "ax1, ax2 = axes\n",
    "\n",
    "sns.lineplot(x=[i for i in range(1,10)], y= [i for i in f1_depth_grid.cv_results_['mean_test_score']], ax= ax1)\n",
    "ax1.set_title('Max Depth Grid Results')\n",
    "ax1.fill_between(x=[i for i in range(1,10)], y1=[i for i in f1_depth_grid.cv_results_['mean_test_score']], y2=min([i for i in f1_depth_grid.cv_results_['mean_test_score']]))\n",
    "ax1.set_xlabel('Max Depth')\n",
    "ax1.set_ylabel('F1 Score')\n",
    "\n",
    "\n",
    "\n",
    "sns.lineplot(x=[i for i in range(1,10)], y= [i for i in roc_depth_grid.cv_results_['mean_test_score']],color='#de525b', ax=ax2)\n",
    "ax2.set_title('Max Depth Grid Results')\n",
    "ax2.fill_between(x=[i for i in range(1,10)], y1=[i for i in roc_depth_grid.cv_results_['mean_test_score']], y2=min([i for i in roc_depth_grid.cv_results_['mean_test_score']]),color='#de525b')\n",
    "ax2.set_xlabel('Max Depth')\n",
    "ax2.set_ylabel('ROC AUC Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase depth, F1 Score and ROC AUC also increase. This is intuitive as the added layers allow for additional decision points to be made and greater order to be derived from the dataset. In continuing the theme of simiplicity I'll use a depth of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch the contstraints of the DecisonTree algroithm, note the decision to limit depth in order to keep a relatively simple decision structure\n",
    "\n",
    "grid_params = {\n",
    "               'min_samples_leaf' : [i for i in range(1,100)] ,\n",
    "               'min_samples_split' : [i for i in range(115,136)]}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state = 42,\n",
    "                            class_weight={0:0.62790406, 1:2.45459008}, max_depth=4, criterion='entropy'), grid_params, cv=5, scoring='roc_auc', error_score=np.nan, n_jobs=-1)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print('Best Score: ' + str(grid.best_score_))\n",
    "print('Best Esitmator: ' +str(grid.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipe(DecisionTreeClassifier(class_weight={0: 0.62790406, 1: 2.45459008},\n",
    "                       criterion='entropy', max_depth=4, min_samples_leaf=50,\n",
    "                       min_samples_split=115, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(class_weight={0: 0.62790406, 1: 2.45459008},\n",
    "                       criterion='entropy', max_depth=4, min_samples_leaf=50,\n",
    "                       min_samples_split=115, random_state=42)\n",
    "dt.fit(X, y)\n",
    "\n",
    "fig = plt.figure(figsize=(40,20))\n",
    "_ = plot_tree(dt, \n",
    "                   feature_names=X.columns,  \n",
    "                   class_names=['Current', 'Churned'],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model\n",
    "\n",
    "with open('dec_tree.pickle', 'wb') as to_write:\n",
    "    pickle.dump(dt, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Results\n",
    "Switching to a tree model provided a small gain in model performance. Minor improvements in Accuracy, Precision, Recall and F1 were experienced, as utilizng the Decision Tree solution of choosing parameters that can provided the greatest reduction in Entropy were the better fit for the data provided.\n",
    "\n",
    "The .5 threshold garners a .56 F1 score between .46 Precision and .72 Recall. So of the observations the model classifies as being 'Exited' it is correct 46% of the time. And of the tested observations, those that actually 'Exited' are classified so 72% of the time. In observing the precision-recall curse, we can see how adjustments of the decision threshold can affect the interplay between Precision-Recall and thusly F1.\n",
    "\n",
    "In observing the decision tree that was generated from the model, we see Age (<=41.5) as the first parameter in which the model gained the most information. Followed by the Number of Products (<=2.5) and their Actiivty status. Looking at the feature importances produced, we see Age and Number of Products were the most powerful decision parameters (were weighted the highest from the full tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "##### Main Takeaway\n",
    "*Age* - From this exercise in Inferential modeling, we see strong indicated that Age the primary indicator of churn among the Bank's customers. The relationship is positively correlated, so as customers get older they become more and more likely to leave the Bank (10 years resulted in 20% increase in churn according to LogisticRegressor). This could be due to Products or Services not meeting the investment needs at the clientel are reaching middle age. There could be interest in funds or investment opporunities for this children that are not met by the bank.\n",
    "\n",
    "<br />\n",
    "\n",
    "###### Needle Movers\n",
    "*Is Active Member* - Found in both models, the binary input of having account transaction activity shows to support Customer longevity. This metric can be seen as proxy for engagement, proving that even passive services such as banking still can improve their stickyness. This proves true in that engagement allows for customers to experience the product/service's value proposition and potentnially convert to higher levels service loyalty.\n",
    "\n",
    "*Germany* - Modeling data along with EDA showed higher rates of churn among German customers. This was surprising as my pursumption is that EU banking laws would incentive international investment whenever possible. Lets look into this further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Exited','Germany','France','Spain']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking accross the three countries, the only variable that stands out is Germany's Balance. The magnitude of which is likely due to lack of 0 balances then higher average balances for each member. Let's confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BalanceZero'] = df.Balance.apply(lambda x: 1 if x == 0 else 0)\n",
    "df.groupby(['Exited','Germany','France','Spain'])['BalanceZero'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed all German observation have a non-zero balance associated with them. This pattern would be indicative to a sevice mandate requiring a balance of X amount held within a customer account at all times (min Balance value of German customers is 27288.43&euro;) This requirement while likely being a barrier to entry for the service also proves to be pushing customers out at higher rate then their Spanish and French peers.\n",
    "\n",
    "Next Step: 4/4 Prediction Modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
